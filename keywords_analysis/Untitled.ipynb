{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3541b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../custom_library')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "\n",
    "import connect_to_db as cn\n",
    "\n",
    "\n",
    "def get_top_keywords(filename):\n",
    "\n",
    "    with open(f'../keywords_analysis/csv/keywords/{filename}', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        keywords_pair = list(reader)\n",
    "        \n",
    "    top_keywords = []\n",
    "    for pair in keywords_pair:\n",
    "        top_keywords.append(pair[0])\n",
    "        \n",
    "    return keywords_pair, top_keywords\n",
    "\n",
    "\n",
    "def top_keywords_main(filenames):\n",
    "    hub_pair, hub_top_keywords = get_top_keywords(filenames[0])\n",
    "    normal_pair, normal_top_keywords = get_top_keywords(filenames[1])\n",
    "\n",
    "    hub_top_50 = set(hub_top_keywords[:300]) - set(normal_top_keywords[:300])\n",
    "    normal_top_50 = set(normal_top_keywords[:300]) - set(hub_top_keywords[:300])\n",
    "\n",
    "    hub_top_50_pair = []\n",
    "    normal_top_50_pair = []\n",
    "\n",
    "    for pair in hub_pair:\n",
    "        for word in hub_top_50:\n",
    "            if pair[0] == word:\n",
    "                hub_top_50_pair.append(pair)\n",
    "            \n",
    "    for pair in normal_pair:\n",
    "        for word in normal_top_50:\n",
    "            if pair[0] == word:\n",
    "                normal_top_50_pair.append(pair)            \n",
    "            \n",
    "    hub_top_50_df = pd.DataFrame(hub_top_50_pair)\n",
    "    normal_top_50_df = pd.DataFrame(normal_top_50_pair)\n",
    "\n",
    "    hub_top_50_df.to_csv(f\"../keywords_analysis/csv/keywords/top_50_{filenames[0]}\", header=None, index=None)\n",
    "    normal_top_50_df.to_csv(f\"../keywords_analysis/csv/keywords/top_50_{filenames[1]}.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873124c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_keywords_main(['keywords_get_hub.csv', 'keywords_get_normal.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bdf6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../keywords_analysis/csv/keywords/top_50_keywords_hub.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    hub_pairs = list(reader)\n",
    "    \n",
    "with open(f'../keywords_analysis/csv/keywords/top_50_keywords_normal.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    normal_pairs = list(reader)\n",
    "        \n",
    "hub_top_50 = []\n",
    "normal_top_50 = []\n",
    "    \n",
    "for h_pair, n_pair in zip(hub_pairs, normal_pairs):\n",
    "    hub_top_50.append(h_pair[0])\n",
    "    normal_top_50.append(n_pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99a7f09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['treat'], ['overcoming'], ['overview'], ['bud'], ['tips'], ['effects'], ['voices'], ['meditation'], ['dissociation'], ['general'], ['cbt'], ['boundaries'], ['psychotic'], ['suggest'], ['delusions'], ['recovery'], ['posts'], ['talked'], ['hallucinations'], ['mania'], ['set'], ['shame'], ['article'], ['food'], ['rule'], ['therapists'], ['lose'], ['movie'], ['related'], ['system'], ['term'], ['date'], ['heal'], ['plan'], ['harm'], ['behavior'], ['medical'], ['dose'], ['intrusive'], ['motivation'], ['bring'], ['act'], ['specific'], ['lack'], ['erp'], ['parent'], ['questions'], ['choice'], ['suck'], ['avoid']]\n"
     ]
    }
   ],
   "source": [
    "hub_word_comment_list = []\n",
    "for i in range(50):\n",
    "    hub_word_comment_list.append([hub_top_50[i]])\n",
    "print(hub_word_comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee9ffb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['boat'], ['sending'], ['omg'], ['constantly'], ['husband'], ['dream'], ['adhd'], ['everyday'], ['crying'], ['play'], ['finally'], ['message'], ['deep'], ['writing'], ['mate'], ['girlfriend'], ['stopped'], ['morning'], ['vent'], ['internet'], ['forever'], ['room'], ['wake'], ['extremely'], ['baby'], ['valid'], ['buddy'], ['comment'], ['shitty'], ['ugly'], ['relatable'], ['fucked'], ['yesterday'], ['posting'], ['attack'], ['text'], ['older'], ['add'], ['word'], ['christmas'], ['miss'], ['asked'], ['inside'], ['funny'], ['eating'], ['dead'], ['watching'], ['died'], ['wife'], ['quarantine']]\n"
     ]
    }
   ],
   "source": [
    "normal_word_comment_list = []\n",
    "for i in range(50):\n",
    "    normal_word_comment_list.append([normal_top_50[i]])\n",
    "print(normal_word_comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63fcdc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84716\n",
      "74591\n"
     ]
    }
   ],
   "source": [
    "with open(f'../keywords_analysis/csv/keys/hub_comment_keys_and_words.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        result = list(reader)\n",
    "        \n",
    "keys_and_words = []\n",
    "for r in result:\n",
    "    if r not in keys_and_words:\n",
    "        keys_and_words.append(r)\n",
    "        \n",
    "print(len(result))\n",
    "print(len(keys_and_words))\n",
    "        \n",
    "for words in keys_and_words:\n",
    "    for word in words[1:]:\n",
    "            for i in range(50):\n",
    "                if hub_top_50[i] == word:\n",
    "                    hub_word_comment_list[i].append(words[0])\n",
    "                    break\n",
    "\n",
    "hub_words_and_keys_df = pd.DataFrame(hub_word_comment_list)\n",
    "# hub_words_and_keys_df.to_csv(f\"../keywords_analysis/csv/keys/hub_words_and_keys.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfc4e418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102149\n",
      "88362\n"
     ]
    }
   ],
   "source": [
    "with open(f'../keywords_analysis/csv/keys/normal_comment_keys_and_words.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        result = list(reader)\n",
    "        \n",
    "keys_and_words = []\n",
    "for r in result:\n",
    "    if r not in keys_and_words:\n",
    "        keys_and_words.append(r)\n",
    "        \n",
    "print(len(result))\n",
    "print(len(keys_and_words))\n",
    "\n",
    "for words in keys_and_words:\n",
    "    for word in words[1:]:\n",
    "            for i in range(50):\n",
    "                if normal_top_50[i] == word:\n",
    "                    normal_word_comment_list[i].append(words[0])\n",
    "                    break\n",
    "\n",
    "normal_words_and_keys_df = pd.DataFrame(normal_word_comment_list)\n",
    "# normal_words_and_keys_df.to_csv(f\"../keywords_analysis/csv/keys/normal_words_and_keys.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434453f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_top_50_df.to_csv(f\"../keywords_analysis/csv/keywords/top_50_{filenames[0]}\", header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
